# -*- coding: utf-8 -*-
"""499A Inception network.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11ezWI7kbmw8HLhwch04Ng1ZQPR_Ld-xz
"""

!pip install -U -q PyDrive

from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
# Authenticating and creating the Drive client
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

df = drive.CreateFile({'id': '13LZcIgT0m4SafyGE3nfOlIjF6Hvlfyw7'})
df.GetContentFile('roads.zip')
!unzip roads.zip

import glob

bad_img = glob.glob('roads/bad/*.*')
good_img = glob.glob('roads/good/*.*')

Y = []
for i in bad_img:
  Y.append(0)

for i in good_img:
  Y.append(1)

import numpy as np
Y=np.asarray(Y)

import pandas as pd
Y = pd.get_dummies(Y).to_numpy()
Y.shape

imgg_arr=[]
import tensorflow as tf
for i in bad_img:
    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', target_size=None)
    image=np.array(image)
    imgg_arr.append(image)

for i in good_img:
    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', target_size=None)
    image=np.array(image)
    imgg_arr.append(image)

#deciding pixel values from image samples
#def pixel_decider(arr): 
 # count_1=0
 # count_2=0
 # count=0
 # for i in imgg_arr:
 #   count=count+1
 #   f_pixel=int(i.shape[0])
 #   count_1=count_1+f_pixel   # returns average pixel values from sample set.
 #   s_pixel=int(i.shape[1])   # This method needs very high computational power when the sample set has large pixel values.
 #   count_2=count_2+s_pixel
 # count_1=int(count_1/count)
 # count_2=int(count_2/count)  
 # return count_1,count_2

#deciding pixel values from image samples
def pixel_decider(arr): 
	f_pixel=int(arr[0].shape[0])
	s_pixel=int(arr[0].shape[1])
	for i in arr:                    # returns minimum pixel values from sample set.
		if f_pixel > (i+1).shape[0]:
			f_pixel=int((i+1).shape[0])
		if s_pixel > (i+1).shape[1]:
			s_pixel=int((i+1).shape[1])
	return f_pixel,s_pixel

first_pixel,second_pixel=pixel_decider(imgg_arr) #calling method
print("first pixel:",first_pixel)
print("second pixel:",second_pixel)

#now resizing image samples
from skimage.transform import resize
ImgArray=[]
for i in imgg_arr:
  resized_img = resize(i,(first_pixel,second_pixel))
  ImgArray.append(resized_img.astype('float32'))

ImgArray=np.asarray(ImgArray)

ImgArray.shape

#cross validation
from sklearn.model_selection import train_test_split,KFold
kf=KFold(10,True,1)
for train_index,test_index in kf.split(ImgArray):
    print("Train Index: ", train_index)
    print("Test Index: ", test_index)
    print("\n")

print(train_index.shape)

X_train, X_test, y_train, y_test = ImgArray[train_index], ImgArray[test_index], Y[train_index], Y[test_index]

# creating the network
from keras.models import Model
from keras.layers import Input
from keras.layers import Conv2D
from keras.layers import MaxPooling2D,Flatten,Dense
from keras.layers.merge import concatenate
from keras.utils import plot_model
 
# function for creating a projected inception module
def inception_module(layer_in, f1, f2_in, f2_out, f3_in, f3_out, f4_out):
	#1x1 conv
	conv1 = Conv2D(f1, (1,1), padding='same', activation='relu')(layer_in)
	# 3x3 conv
	conv3 = Conv2D(f2_in, (1,1), padding='same', activation='relu')(layer_in)
	conv3 = Conv2D(f2_out, (3,3), padding='same', activation='relu')(conv3)
	# 5x5 conv
	conv5 = Conv2D(f3_in, (1,1), padding='same', activation='relu')(layer_in)
	conv5 = Conv2D(f3_out, (5,5), padding='same', activation='relu')(conv5)
	# 3x3 max pooling
	pool = MaxPooling2D((3,3), strides=(1,1), padding='same')(layer_in)
	pool = Conv2D(f4_out, (1,1), padding='same', activation='relu')(pool)
	#concatenate layer
	concated_layer = concatenate([conv1, conv3, conv5, pool], axis=-1)
	#creating output shape
	pooling=MaxPooling2D(pool_size=(2, 2))(concated_layer)
	flattened = Flatten()(pooling)
	fully_connected = Dense(2, activation='softmax')(flattened)
	return fully_connected

                                                                       # For 1 inception block
# define model input
visible = Input(shape=(first_pixel, second_pixel, 3))
# add inception block 1
layer = inception_module(visible, 32, 64, 64, 16, 32, 32)
# create model
model = Model(inputs=visible, outputs=layer)
# summarize model
model.summary()
# plot model architecture
plot_model(model, show_shapes=True, to_file='inception_module.png')

from keras.losses import categorical_crossentropy
from keras.optimizers import Adam
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

model.fit(X_train,y_train,batch_size=64,epochs=10,verbose=1, validation_data=(X_test,y_test))

scores = model.evaluate(X_test, y_test, verbose=0)
print("Accuracy: %.2f%%" % (scores[1]*100))

# creating the network
from keras.models import Model
from keras.layers import Input
from keras.layers import Conv2D
from keras.layers import MaxPooling2D,Flatten,Dense
from keras.layers.merge import concatenate
from keras.utils import plot_model
 
# function for creating a projected inception module
def inception_module(layer_in, f1, f2_in, f2_out, f3_in, f3_out, f4_out):
	#1x1 conv
	conv1 = Conv2D(f1, (1,1), padding='same', activation='relu')(layer_in)
	# 3x3 conv
	conv3 = Conv2D(f2_in, (1,1), padding='same', activation='relu')(layer_in)
	conv3 = Conv2D(f2_out, (3,3), padding='same', activation='relu')(conv3)
	# 5x5 conv
	conv5 = Conv2D(f3_in, (1,1), padding='same', activation='relu')(layer_in)
	conv5 = Conv2D(f3_out, (5,5), padding='same', activation='relu')(conv5)
	# 3x3 max pooling
	pool = MaxPooling2D((3,3), strides=(1,1), padding='same')(layer_in)
	pool = Conv2D(f4_out, (1,1), padding='same', activation='relu')(pool)
	#concatenate layer
	concated_layer = concatenate([conv1, conv3, conv5, pool], axis=-1)
	return concated_layer

                                                                          # For 2 inception block
# define model input
visible = Input(shape=(first_pixel, second_pixel, 3))
# add inception block 1
layer = inception_module(visible, 16, 32, 32, 16, 32, 32)
# add inception block 2
layer = inception_module(layer, 16, 16, 32, 32, 64, 64)
#creating output shape
pooling=MaxPooling2D(pool_size=(2, 2),strides=(2, 2))(layer)
flattened = Flatten()(pooling)
fully_connected = Dense(2, activation='softmax')(flattened)
# create model
model = Model(inputs=visible, outputs=fully_connected)
# summarize model
model.summary()
# plot model architecture
plot_model(model, show_shapes=True, to_file='inception_module.png')

from keras.losses import categorical_crossentropy
from keras.optimizers import Adam
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

model.fit(X_train,y_train,batch_size=15,epochs=10,verbose=1, validation_data=(X_test,y_test))

scores = model.evaluate(X_test, y_test, verbose=0)
print("Accuracy: %.2f%%" % (scores[1]*100))

# testing a single photo
photo_test=X_test[1]

from skimage.io import imread, imshow
import matplotlib.pyplot as plt
imshow(photo_test)
print("Actual Image.")

model.predict(X_test[1:2]) # model predicts this image as [1, 0] because probability is high at first position [91.5%,  8.4%]

y_test[1:2]   # this is actual true value [1, 0].