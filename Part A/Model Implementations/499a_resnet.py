# -*- coding: utf-8 -*-
"""499A Resnet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GtfdxUS6aQeIJPrTHFdepxgyBo7cBqSF
"""

!pip install -U -q PyDrive

from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
# Authenticating and creating the Drive client
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

df = drive.CreateFile({'id': '1fsAmPhxeKkmbGP8ymW6DImPg-ZgifdLU'})
df.GetContentFile('roads.zip')
!unzip roads.zip

import glob

bad_img = glob.glob('roads/bad/*.*')
good_img = glob.glob('roads/good/*.*')

Y = []
for i in bad_img:
  Y.append(0)
   
for i in good_img:
  Y.append(1)

import numpy as np
classes=Y # saving classes to apply stratified cross-validation later

import numpy as np
Y=np.asarray(Y)

import pandas as pd
Y = pd.get_dummies(Y).to_numpy()
Y.shape

imgg_arr=[]
import tensorflow as tf
for i in bad_img:
    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', target_size=None)
    image=np.array(image)
    imgg_arr.append(image)

for i in good_img:
    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', target_size=None)
    image=np.array(image)
    imgg_arr.append(image)

#deciding pixel values from image samples
def pixel_decider(arr): 
	f_pixel=int(arr[0].shape[0])
	s_pixel=int(arr[0].shape[1])
	for i in arr:                    # returns minimum pixel values from sample set.
		if f_pixel > (i+1).shape[0]:
			f_pixel=int((i+1).shape[0])
		if s_pixel > (i+1).shape[1]:
			s_pixel=int((i+1).shape[1])
	return f_pixel,s_pixel

first_pixel,second_pixel=pixel_decider(imgg_arr) #calling method
print("first pixel:",first_pixel)
print("second pixel:",second_pixel)

#now resizing image samples
from skimage.transform import resize
ImgArray=[]
for i in imgg_arr:
  resized_img = resize(i,(first_pixel,second_pixel))
  ImgArray.append(resized_img.astype('float32'))

ImgArray=np.asarray(ImgArray)

ImgArray.shape

def Img_Augmentor(Img_Array,Y_Array,num_of_Img,num_of_aug): # Augmentation method
  
  from keras.preprocessing.image import ImageDataGenerator
  datagen = ImageDataGenerator(rotation_range=40,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        fill_mode='nearest') 
  
  # random index generator
  indx_arr=[]        
  from random import randint
  for _ in range(num_of_Img):
	  value = randint(0, len(Img_Array)-1)
	  indx_arr.append(value)
  selected_img=Img_Array[indx_arr] # randomly selected image

  agg=[] # augmented Image array
  for i in selected_img:
    aaa=i.reshape((1,)+i.shape)
    aug_d=datagen.flow(aaa)
    aug_img=[next(aug_d)[0].astype(np.float32) for i in range(num_of_aug)]
    for j in range(0,len(aug_img)):
      agg.append(aug_img[j])

  agg=np.asarray(agg) # (3000, 48, 48, 3)

  #merging augmented image with normal image
  Img_Array=np.array(Img_Array)
  augmented_image=np.array(agg)
  new_Img_Arr=np.append(Img_Array,augmented_image,axis=0)
  #new_Img_Arr=np.around(new_Img_Arr, decimals=3) # 3 decimal point
 
  ## preparing Y_train
  Y_new=Y_Array
  y_tmp=Y_Array[indx_arr]
  keep_y=[] # copying original Y_train to keep_y
  for i in Y_new:
    keep_y.append(i)
  for i in y_tmp: # merging original Y and augmented Y
    for j in range(0,(num_of_aug)):
      keep_y.append(i)
  new_y_Arr=np.asarray(keep_y)  
    
  return new_Img_Arr,new_y_Arr,indx_arr  # Method ends

augmented_x,augmented_y,photo_indexes=Img_Augmentor(ImgArray,Y,100,2) #method call

augmented_x.shape

augmented_y.shape

classes=np.asarray(classes)  # preparing class values for stratified cross-validation
values=classes[photo_indexes]
values=np.asarray(values)

tmp_arr=[]
for i in values:  # adjusting class values
  for j in range(0,2):
    tmp_arr.append(i)
tmp_arr=np.asarray(tmp_arr)

tmp_arr.shape

my_classes=np.append(classes,tmp_arr,axis=0)

my_classes.shape

import keras
from keras.layers import Dense, Conv2D, BatchNormalization, Activation
from keras.layers import AveragePooling2D, Input, Flatten
from keras.optimizers import Adam
from keras.regularizers import l2
from keras.models import Model

## building the network
def resnet_layer(inputs,num_filters=16,kernel_size=3,strides=1,activation='relu',batch_normalization=True,conv_first=True):
     
    conv = Conv2D(num_filters,kernel_size=kernel_size,strides=strides,padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(1e-4))

    x = inputs
    if conv_first:
        x = conv(x)
        if batch_normalization:
            x = BatchNormalization()(x)
        if activation is not None:
            x = Activation(activation)(x)
    else:
        if batch_normalization:
            x = BatchNormalization()(x)
        if activation is not None:
            x = Activation(activation)(x)
        x = conv(x)
    return x

def resnet_v1(input_shape, depth, num_classes=2):
    
    if (depth - 2) % 6 != 0:
        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')
    # Start model definition.
    num_filters = 16
    num_res_blocks = int((depth - 2) / 6)

    inputs = Input(shape=input_shape)
    x = resnet_layer(inputs=inputs)
    # Instantiate the stack of residual units
    for stack in range(3):
        for res_block in range(num_res_blocks):
            strides = 1
            if stack > 0 and res_block == 0:  # first layer but not first stack
                strides = 2  # downsample
            y = resnet_layer(inputs=x,num_filters=num_filters,strides=strides)
            y = resnet_layer(inputs=y,num_filters=num_filters,activation=None)
            if stack > 0 and res_block == 0:  # first layer but not first stack
                # linear projection residual shortcut connection to match
                # changed dims
                x = resnet_layer(inputs=x,num_filters=num_filters,kernel_size=1,strides=strides,activation=None,batch_normalization=False)
            x = keras.layers.add([x, y])
            x = Activation('relu')(x)
        num_filters *= 2

    # Add classifier on top.
    x = AveragePooling2D(pool_size=8)(x)
    y = Flatten()(x)
    outputs = Dense(num_classes,
                    activation='softmax',
                    kernel_initializer='he_normal')(y)

    # Instantiate model.
    model = Model(inputs=inputs, outputs=outputs)
    return model

model = resnet_v1(input_shape=(first_pixel,second_pixel,3), depth=32)

model.summary()

from keras.losses import categorical_crossentropy
from keras.optimizers import Adam

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

augmented_y = augmented_y.astype(int)

# Training the model using K=5 fold cross-validation
Predict_list=[]
from sklearn.model_selection import KFold
from sklearn.model_selection import StratifiedKFold
from sklearn import metrics
fold=0
kf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)
for train_index, test_index in kf.split(augmented_x,my_classes):
   fold+=1
   print("Fold:",fold," ","TRAIN:", train_index, "TEST:", test_index)
   X_train, X_test = augmented_x[train_index], augmented_x[test_index]
   y_train, y_test = augmented_y[train_index], augmented_y[test_index]
   model.fit(X_train,y_train,batch_size=15,epochs=10,verbose=1, validation_data=(X_test,y_test))
   score=model.evaluate(X_test, y_test, verbose=0)
   Predict_list.append(score)

print(Predict_list)

accuracy=0
for i in Predict_list:
  accuracy=accuracy+i[1]
accuracy=accuracy / 5   #as k=5 fold

print("Accuracy: %.2f%%" % (accuracy*100))

# testing a single photo from test set
photo_test=X_test[7]

from skimage.io import imread, imshow
import matplotlib.pyplot as plt
imshow(photo_test)
print("Actual Image.")

model.predict(X_test[7:8]) # model predicts this image as [0, 1] 
                           # because probability is high in the second position [0.00026%,  99.97%]

y_test[7:8]   # this is actual true value [0, 1].